
% [computermodern], 
% \documentclass[numbers]{sigplanconf}
\documentclass[10pt,preprint,twocolumn]{acmart}

\usepackage[T1]{fontenc}
\usepackage{libertine}%% Only as example for the romans/sans fonts
\usepackage[scaled=0.85]{beramono}

\usepackage{url}
% \usepackage{code}
% \usepackage{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{chessboard}

% \usepackage{chessfs}
\usepackage{adjustbox}

% Define black versions of pieces for inline use. Gross, but it works.
\newcommand{\Pawn}[1][1.3ex]{%
\adjustbox{Trim=4.3pt 2.6pt 4.3pt 0pt,width=#1,margin=0.2ex 0ex 0.2ex 0ex}{\BlackPawnOnWhite}%
}%
\newcommand{\Rook}[1][1.58ex]{%
\adjustbox{Trim=3.2pt 2.2pt 3.2pt 0pt,width=#1,raise=0ex,margin=0.1ex 0ex 0.1ex 0ex}{\BlackRookOnWhite}%
}%
\newcommand{\Knight}[1][1.85ex]{%
\adjustbox{Trim=2.3pt 2.35pt 2.5pt 0pt,width=#1,raise=-0.03ex,margin=0.14ex 0ex 0.14ex 0ex}{\BlackKnightOnWhite}%
}%
\newcommand{\Bishop}[1][1.79ex]{%
\adjustbox{Trim=2.3pt 2pt 2.3pt 0pt,width=#1,raise=-0.12ex,margin=0.1ex 0ex 0.1ex 0ex}{\BlackBishopOnWhite}%
}%
\newcommand{\Queen}[1][2.05ex]{%
\adjustbox{Trim=1.2pt 2.2pt 1.2pt 0pt,width=#1,raise=-0.08ex,margin=0.1ex 0ex 0.1ex 0ex}{\BlackQueenOnWhite}%
}%
\newcommand{\King}[1][1.95ex]{%
\adjustbox{Trim=2pt 2pt 2pt 0pt,width=#1,raise=-0.06ex,margin=0.13ex 0ex 0.13ex 0ex}{\BlackKingOnWhite}%
}%

\interfootnotelinepenalty=0

% lets me explicitly set a. or 1. etc. as enum label
\usepackage{enumitem}

\pagestyle{empty}

\usepackage{ulem}
% go back to italics for emphasis, though
\normalem

\usepackage{natbib}

\setlength{\footnotesep}{2em}

% \newcommand\comment[1]{}
\newcommand\sfrac[2]{\!{}\,^{#1}\!/{}\!_{#2}}

% skip acm copyright shits
\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\setcopyright{none}

\begin{document} 

% \copyrightyear{2019}

\acmConference{SIGBOVIK~2019}{April 1, 2019, Pittsburgh, Pennsylvania, USA}

\title[Elo World]{Elo World, a framework for \\ benchmarking weak chess \\ engines}
% \authorinfo{Dr. Tom Murphy VII Ph.D.}{tom7.org Foundation}{tom7@tom7.org}
\author{Dr. Tom Murphy VII Ph.D.}\email{tom7@tom7.org}
\thanks{Copyright \copyright\ 2019 the Regents of the Wikiplia Foundation.
Appears in SIGBOVIK 19119 with the
%
title inflation
%
of the Association for Computational Heresy; {\em IEEEEEE!}
press, Verlag-Verlag volume no.~0x40-2A. 1600 rating points}

\ccsdesc[500]{Evaluation methodologies~Tournaments}
\ccsdesc[500]{Chess~Being bad at it}
% \ccsdesc[100]{Software and its engineering~Control structures}
% \ccsdesc[300]{Theory of computation~Control primitives}

\keywords{pawn, horse, bishop, castle, queen, king}
% \keywords{chess, bad}

\setchessboard{showmover=false}

\newcommand\checkmate{\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}

\renewcommand\th{\ensuremath{{}^{\textrm{th}}}}
\newcommand\st{\ensuremath{{}^{\textrm{st}}}}
\newcommand\rd{\ensuremath{{}^{\textrm{rd}}}}
\newcommand\nd{\ensuremath{{}^{\textrm{nd}}}}
\newcommand\at{\ensuremath{\scriptstyle @}}

\date{1 April 2019}

\maketitle \thispagestyle{empty}

\section{Introduction}

Fiddly bits aside, it is a solved problem to maintain a numeric skill
rating of players for some game (for example chess, but also sports,
e-sports, probably also z-sports if that's a thing). Though it has
some competition (suggesting the need for a meta-rating system to
compare them), the Elo Rating System~\cite{elo1978rating} is a simple
and effective way to do it. This paper is concerned with Elo in chess,
its original purpose.

The gist of this system is to track a single score for each player.
The scores are defined such that the expected outcomes of games can be
computed from the scores (for example, a player with a rating of 2400
should win 9/10 of her games against a player with a rating of 2000).
If the true outcome (of e.g.~a tournament) doesn't match the expected
outcome, then both player's scores are adjusted towards values that
would have produced the expected result. Over time, scores thus become
a more accurate reflection of players' skill, while also allowing for
players to change skill level. This system is carefully described
elsewhere, so we can just leave it at that.

The players need not be human, and in fact this can facilitate running
many games and thereby getting arbitrarily accurate ratings.

The problem this paper is concerned with is that basically all chess
tournaments (whether with humans or computers or both) are between
players who know how to play chess, are interested in winning their
games, and have some reasonable level of skill. This makes it hard to
give a rating to weak players: They just lose every single game and so
tend towards a rating of $-\infty$\footnote{Some organizations don't
  even let ratings fall beneath a certain level, for example, the
  lowest possible USCF rating is 100.} Even if other comparatively
weak players existed to participate in the tournament and occasionally
lose to the player under study, it may still be difficult to
understand how this cohort performs in any absolute sense. (In
contrast we have ``the highest ever human rating was 2882,'' and
``there are 5,323 players with ratings in 2200--2299'' and ``Players
whose ratings drop below 1000 are listed on the next list as
'delisted'.''~\cite{fideratings}) It may also be the case that all
weak players always lose to all strong players, making it unclear just
how wide the performance gap between the two sets is. The goal of
this paper is to expand the dynamic range of chess ratings to span
all the way from extremely weak players to extremely strong ones, while
providing canonical reference points along the way.

\section{Elo world}

Elo World is a tournament with dozens of computer players. The
computer players include some traditional chess engines, but also many
algorithms chosen for their simplicity, as well as some designed to
be competitively bad.

The fun part is the various algorithms, so let's get into that. First,
some ground rules and guidelines:
\begin{itemize}
\item No resigning (forfeiting) or claiming a draw. The player will
  only be asked to make a move when there exists one, and it must
  choose a move in finite time. (In practice, most of the players are
  extremely fast, with the slowest ones using about one second of
  CPU time per move.)
\item The player can retain state for the game, and executes moves
  sequentially (for either the white or black pieces), but cannot have
  state meaningfully span games. For example, it is not permitted to
  do man-in-the-middle attacks~\cite{blind} or learn opponent's moves
  from previous rounds, or to get better at chess. The majority of
  players are actually completely stateless, just a function of type
  ${\tt position} \rightarrow {\tt move}$.
\item black and white behave the same
\item Avoid game-tree search. Minimax, alpha--beta, etc. are the
  correct way to play chess programmatically. They are well-studied
  (i.e., boring) and effective, and so not well suited to our problem.
  A less obvious issue is that they are endlessly parameterizable, for
  example the search ply; this leaves us with a million things to
  fiddle with. In any case, several traditional chess engines are
  included for comparison.
\end{itemize}

% dispense with alpha-beta, etc.

\subsection{The players}

\newcommand\describeplayer[1]{\smallskip\noindent {\texttt{\textbf{#1}}}.\quad}
\newcommand\player[1]{\texttt{#1}}
\newcommand\deterministic{\colorbox{black}{\color{white} \textsf{det}}}
\newcommand\traditional{\colorbox{black}{\color{white} \textsf{trad}}}
% funny to use that v symbol made of leaves
\newcommand\vegetarian{\colorbox{black}{\color{white} \textsf{v}}}
\newcommand\canonical{\colorbox{black}{\color{white} \textsf{canon}}}
\newcommand\stateful{\colorbox{black}{\color{white} \textsf{state}}}
\newcommand\asymmetric{\colorbox{black}{\color{white} \textsf{asym}}}

\describeplayer{random} We must begin with the most canonical of all
strategies: Choosing a legal move uniformly at random. This is a
lovely choice for Elo World, for several reasons: It is simple to
describe. It is clearly canonical, in that anyone undertaking a
similar project would come up with the same thing. It is capable of
producing any sequence of moves, and thus completely spans the gamut
from the worst possible player to the best. If we run the tournament
long enough, it will eventually draw games even against a hypothetical
perfect opponent, a sort of Boltzmann Brilliancy. Note that this
strategy actually does keep state (the pseudorandom pool), despite the
admonition above. We can see this as not really state but a simulation
of an external source of ``true'' randomness. Most other players
fall back on making random moves to break ties or when their primary
strategy does not apply. \canonical

\describeplayer{same\_color} When playing as white, put pieces on
white squares. Vice versa for black. This is accomplished by counting
the number of white pieces on white squares {\em after} each possible
move, and then playing one of the moves that maximizes this number.
Ties are broken randomly. Like many algorithms described this way, it
tends to reach a plateau where the metric cannot be increased in a
single move, and then plays randomly along this local maximum
(Figure~\ref{fig:samecolor}). This particular strategy moves one
knight at most once (because they always change color when moving)
unless forced; on the other hand both bishops can be safely moved
anywhere when the metric is maxed out.

\begin{figure}[ht]
\chessboard[setfen=1n1r3q/1Q2r1bp/1p1p1p1n/p1pPp1p1/P1PkR3/1P1P1P1N/6BP/1N1R3K b - - 85 73,showmover=false]
\caption{\player{same\_color} (playing as white) checkmates
  \player{same\_color} (playing as black) on move 73. Note that since
  white opened with Nh3, the h2 pawn is stuck on a black square.
  Moving the knight out of the way would require that move to be
  forced. } \label{fig:samecolor}
\end{figure}

\describeplayer{opposite\_color} Same idea, opposite parity.

% XXX more clear/efficient description here?
\describeplayer{pacifist} Avoid moves that mate the opponent, and
failing that, avoid moves that check, and failing that, avoid moves
that capture pieces, and failing that, capture lower value pieces.
Break ties randomly. This is one of the worst strategies, drawing
against players that are not ambitious about normal chess pursuits,
and easily losing to simple strategies. On the other hand, it does
rarely get forced into mating its opponent by aggressive but weak
players. \vegetarian

\describeplayer{first\_move} Make the lexicographically first legal
move. The moves are ordered as $\langle$ \verb+src_row+,
\verb+src_col+, \verb+dst_row+, \verb+dst_col+,
\verb+promote_to+ $\rangle$ for white (rank $1$ is row $0$) and the rows
are reversed for black to make the strategy symmetric. Tends to
produce draws (by repetition), because knights and rooks can often
move back and forth on the first few files. \deterministic

\describeplayer{alphabetical} Make the alphabetically first move,
using standard PGN short notation. White and black both try to move
towards A1. \asymmetric \deterministic

\describeplayer{worstfish}
\describeplayer{generous}
\describeplayer{safe}
\describeplayer{popular}
\describeplayer{dangerous}
\describeplayer{rare}
\describeplayer{no\_i\_insist}
\describeplayer{sym\_mirror\_x}
\describeplayer{huddle}
\describeplayer{survivalist}
\describeplayer{sym\_180}
\describeplayer{sym\_mirror\_y}
\describeplayer{suicide\_king}
\describeplayer{reverse\_starting}
\describeplayer{fatalist}
\describeplayer{blind\_yolo}
\describeplayer{cccp}
\describeplayer{equalizer}
\describeplayer{blind\_kings}
\describeplayer{swarm}
\describeplayer{min\_oppt\_moves}
\describeplayer{chessmaster.nes\_lv1}
\describeplayer{stockfish1m\_r32768}
\describeplayer{chessmaster.nes\_lv2}
\describeplayer{stockfish1m\_r16384}
\describeplayer{stockfish0}
\describeplayer{stockfish5}
\describeplayer{stockfish1m\_r8192}
\describeplayer{topple10k}
\describeplayer{stockfish15}
\describeplayer{stockfish10}
\describeplayer{stockfish1m\_r4096}
\describeplayer{stockfish20}
\describeplayer{topple1m}
\describeplayer{stockfish1m\_r2048}
\describeplayer{stockfish1m\_r1024}
\describeplayer{stockfish1m\_r512}
\describeplayer{stockfish1m\_r256}
\describeplayer{stockfish1m\_r64}
\describeplayer{stockfish1m}
\describeplayer{stockfish1m\_r128}

Ideally, such a system would be robust against adding new players,
but this is probably not the case.


% Names:
% "Stalemate"
% "Weaksauce"
% "back rank"
% "blunder"
% something with ..elo..   "elo world"
% inFIDElity
% blunderbuss
% 

Interpolation, like Scoville scale.

% Dramatic failure of the "suicide king" strategy against
% CCCP.
1. d4 g5 2. Bxg5 Nc6 3. Bxe7 Kxe7 4. d5 Kd6
5. dxc6+ Kc5 6. Qd6+ Kc4 7. e4++

% miraculous win for "generous" strategy as black:
% playing against "suicide king". White forces black
% to mate him:
1. a4 b5 2. d3 Nh6 3. Kd2 Ng8 4. Kc3 Nh6
5. Kd4 c6 6. Ke5 f5 7. a5 Qb6 8. Bg5 Qe3+
9. Bxe3 Na6 10. f3 Nc5 11. Ra2 Ne4 12. f4 Nd2
13. Bf2 Nf3+ 14. exf3 Ng4+ 15. Kxf5 g5 16. Nh3 e5
17. Bh4 Ba3 18. b4 e4 19. Nf2 c5 20. c4 Ba6
21. g3 Rc8 22. Be2 Kf7 23. fxe4 d5 24. Qc1 dxe4
25. Rg1 bxc4 26. Rd1 cxd3 27. Qxc5 Rhf8 28. Nd2 Bc4
29. Kxg5 Rc7 30. Bf3 Ke8 31. Qe5+ Kf7 32. Qe6+ Kg7
33. Qb6 Rxf4 34. Nb3 Bb5 35. Qb7 d2 36. Nh3 Bc1
37. Qxa7 Be2 38. Nd4 h5 39. Ra1 Nf2 40. Raxc1 Nh1
41. Rf1 d1=Q 42. Qxc7+ Kh8 43. Kg6 Bc4 44. Bxd1 e3
45. Qf7 Bb3 46. Rf3 Nf2 47. Rc6 e2 48. Rc7 Rf5
49. Rc4 Rf4 50. Nb5 e1=Q 51. Rc2 Qc3 52. g4 Rf5
53. Ng1 Qc7 54. Rcc3 Nd3 55. Rc5 Nf2 56. Nc3 Ba2
57. Qh7+

% worstfish (black) somehow beating suicide king
% white forces the mate. Note that worstfish
% does assume its opponent will pick good moves...
1. Nf3 g5 2. b4 Na6 3. Nxg5 Nc5 4. b5 f6
5. c4 Na6 6. Nf7 Rb8 7. d3 h6 8. Kd2 Nb4
9. Kc3 Rh7 10. Kd4 Rg7 11. Kc5 Nd5 12. Nxh6 Nb4
13. Na3 Rg3 14. Qc2 Bg7 15. f4 a6 16. Qb1 Bh8
17. Qb2 f5 18. Qf6 Rxg2 19. Qh4 Rxe2 20. Bg2 e5
21. Bd2 Bf6 22. Nf7 Bh8 23. Qf2 c6 24. Kd6 Re4
25. h4 Qc7+ 26. Kxc7 Nxa2 27. Raf1 c5 28. Nh6 Ke7
29. Qd4 Ke6 30. Rc1 Bg7 31. Be1 Ra8 32. Rc2 Nc3
33. Ra2 Ne7 34. Qxe4 Bf8 35. Kd8 Nxb5 36. Qxf5+ Kd6
37. Qxd7+ Bxd7++


% Fate-based algorithms.
% The deterministic version is fairly boring, since the
% highest probability states are similar to the starting
% position (this might not be true for "survivalist"
% or "fatalist"? check?)

% weighted random is almost the same as random, because
% the weights tend to be very similar when treated
% additively. They perform slightly different from
% random, as so (101.5 million games):

%  player	elo	w/l/d
%  dangerous	986.29	1374577/1501526/15683897
%  popular	997.34	1360053/1502995/15696952
%  random_move	1000.79	1540798/1337668/15681534
%  rare	1005.85	1554600/1326707/15678693
%  safe	1009.72	1341030/1502162/15716808

% then with normalization:
%  player	elo	w/l/d
%  popular	990.93	25756/43561/346683
%  safe	993.49	28082/40769/347149
%  dangerous	996.60	30063/37451/348486
%  rare	1005.82	50656/27390/337954
%  random_move	1013.15	41747/27133/347120


// Good site for some computer chess programs with ELO:
// http://www.computerchess.org.uk/ccrl/404/


\nocite{elo1978rating}
\nocite{topple}
// citation for knights distance:
\nocite{miller2013counting}

% \balance
% \bibliographystyle{plain}
\bibliographystyle{ACM-Reference-Format}
\bibliography{chess}

\end{document}
