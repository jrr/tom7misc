\documentclass[twocolumn]{amsart}
\usepackage[top=0.5in, left=0.45in, right=0.45in, bottom=0.5in]{geometry}

\usepackage{url}
% \usepackage{code}
% \usepackage{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{chessboard}

% \usepackage{chessfs}
\usepackage{adjustbox}

% Define black versions of pieces for inline use. Gross, but it works.
\newcommand{\Pawn}[1][1.3ex]{%
\adjustbox{Trim=4.3pt 2.6pt 4.3pt 0pt,width=#1,margin=0.2ex 0ex 0.2ex 0ex}{\BlackPawnOnWhite}%
}%
\newcommand{\Rook}[1][1.58ex]{%
\adjustbox{Trim=3.2pt 2.2pt 3.2pt 0pt,width=#1,raise=0ex,margin=0.1ex 0ex 0.1ex 0ex}{\BlackRookOnWhite}%
}%
\newcommand{\Knight}[1][1.85ex]{%
\adjustbox{Trim=2.3pt 2.35pt 2.5pt 0pt,width=#1,raise=-0.03ex,margin=0.14ex 0ex 0.14ex 0ex}{\BlackKnightOnWhite}%
}%
\newcommand{\Bishop}[1][1.79ex]{%
\adjustbox{Trim=2.3pt 2pt 2.3pt 0pt,width=#1,raise=-0.12ex,margin=0.1ex 0ex 0.1ex 0ex}{\BlackBishopOnWhite}%
}%
\newcommand{\Queen}[1][2.05ex]{%
\adjustbox{Trim=1.2pt 2.2pt 1.2pt 0pt,width=#1,raise=-0.08ex,margin=0.1ex 0ex 0.1ex 0ex}{\BlackQueenOnWhite}%
}%
\newcommand{\King}[1][1.95ex]{%
\adjustbox{Trim=2pt 2pt 2pt 0pt,width=#1,raise=-0.06ex,margin=0.13ex 0ex 0.13ex 0ex}{\BlackKingOnWhite}%
}%

\interfootnotelinepenalty=0

% lets me explicitly set a. or 1. etc. as enum label
\usepackage{enumitem}

\pagestyle{empty}

\usepackage{ulem}
% go back to italics for emphasis, though
\normalem

\usepackage{natbib}

\setlength{\footnotesep}{2em}

% \newcommand\comment[1]{}
\newcommand\sfrac[2]{\!{}\,^{#1}\!/{}\!_{#2}}

\begin{document} 

\title{Color- and piece-blind chess}
\author{Dr.~Tom~Murphy~VII~Ph.D.}\thanks{
Copyright \copyright\ 2019 the Regents of the Wikiplia Foundation.
Appears in The Journal Of LaTeX Class Files with the insufficient
material of the Association for Computational Heresy; {\em IEEEEEE!}
press, Verlag-Verlag volume no.~0x40-2A. 1 tempo}

\setchessboard{showmover=false}

\newcommand\checkmate{\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}

\renewcommand\th{\ensuremath{{}^{\textrm{th}}}}
\newcommand\st{\ensuremath{{}^{\textrm{st}}}}
\newcommand\rd{\ensuremath{{}^{\textrm{rd}}}}
\newcommand\nd{\ensuremath{{}^{\textrm{nd}}}}
\newcommand\at{\ensuremath{\scriptstyle @}}

\date{1 April 2019}

\maketitle \thispagestyle{empty}

% \begin{abstract}
% CHESSMATE.
% \end{abstract}

\section{Impressing humans}

What better way for humans to impress each other with their brains,
especially in movies, than to play chess---and to shout dramatically
CHECKMATE! upon surprise-checkmating their opponent? Well, one way is
to play chess while disadvantaged somehow, for example, by punching
each other in the face repeatedly during the game to impair brain
function (see Chess Boxing~\cite{wikipediachessboxing}). Another common
distraction is to play a multitude of games against many opponents at
the same time, in a so-called ``simultaneous exhibition.'' The idea is
that this is more challenging because of the need to maintain mental
state for so many games at once, whereas your opponents only need to
maintain state for one game. In truth, simultaneous exhibitions easily
fall to a ``man-in-the-middle attack.'' If the purported genius simply
creates a bipartite matching of the games played with the white pieces
and the games played with black, he can mechanically forward moves
between these pairs of boards. This requires only constant state (see
next section) per pair of games, and guarantees an even score for the
exhibition. So that's not very impressive.

Another disadvantage that humans sometimes use to impress each other
is a blindfold (worn over the eyes). In this predicament they only
hear the opponent announce moves and must keep the position on the
board in their mind's eye, both for the sake of remembering it and
while exploring potential moves.
% This is effective, since although the .
Disadvantages can be combined, such as in the final scene of the 1988
documentary {\it Bloodsport} where Jean Claude van Damme is blinded by
an illicit foreign substance during the final martial art
battle.\footnote{JCVD does not play chess on camera, but it is implied
  that he is also holding a simultaneous exhibition between rounds in
  a different room of the underground Hong Kong illegal karate
  complex.}
% Note: blindfold simuls are banned in russia as a health hazard!?

\section{Impressing computers}

In contrast, it is much more difficult to impress computers or impress
people with computers. When it comes to computers playing chess,
largely, the jig is up; it is now easy for chess programs, running on
consumer hardware, to defeat the strongest human players. It is well
known that striking a computer actually {\em fixes} it, so chess
boxing becomes trivial. Blindfold chess is the natural interface for a
chess computer; it is actually {\em much more difficult} to have the
computer interpret the opponent's move by visually studying a physical
board!

% Computers can still impress us and each other with computational chess
% feats other than playing. For example, computers are largely concerned
% with filling up their memories with efficiently encoded data.

Playing multiple games simutaneously is an easy extension of playing a
single game, although in principle the scale of such a thing could
still be impressive. With a modern chess engine, it is easy to scale
to an arbitrary number of games, since the exhibitor can make progress
by observing one of the boards, computing a strong move, and playing
it; this requires $O(0)$ space because all of the state is stored
externally in the exhibition itself. 
% If playing blindfold, then the
% main cost is storing the state of each game. 
However, we run the risk of losing the tournament (other players may
be yet stronger computers). The man-in-the-middle attack remains an
efficient way way to minimize loss (ensuring an exactly even score).
The simplest way to do this is to explicily generate a perfect
bipartite matching over the $n$ games $G$ being played. This consists
of $n/2$ pairs $\langle G_w, G_b \rangle$ (where we play as white
against Bob and black against Walice, respectively). Since each game
starts in the starting position, this is very easy; we can just assign
the matches consecutively. Along with each pair we also record which
of the following states we are in:
\begin{enumerate}
\item We are waiting for a move from Walice (our white opponent) \label{state:mim1}
\item We have seen a move from Walice, which is \underline{\hspace{6em}}. \label{state:mim2}
\item We are waiting for a move from Bob (our black opponent) \label{state:mim3}
\item We have seen a move from Bob, which is \underline{\hspace{6em}}. \label{state:mim4}
\end{enumerate}
If in State~\ref{state:mim1}, we just watch $G_b$ until Walice makes a
move, then record it and proceed to State~\ref{state:mim2}. We consume
the move and move to State~\ref{state:mim3} by playing that move in
$G_w$ against Bob (where it must be our turn). We can immediately seek
out that game or wait until we naturally come upon it. However, we
should only approach $G_w$ when the pair of games is in
State~\ref{state:mim3}, etc., otherwise we will not have a move to play.

There are $n/2$ pairs, with two bits for the state, no more\footnote{
  There are only 1792 pairs of squares between which pieces can ever
  move (Section~\ref{sec:legalmove}), so $11+2$ bits suffices, with
  some added complexity.} than $\log_2(64 \times 64 \times 4) = 14$ bits for
each move (source square, destination square, and 2 bits to
distinguish promotion to queen, rook, bishop, or knight). However, we
also need to store the matching of $G_w$ to $G_b$; this can be done
with a pair of indices (or e.g. memory addresses) but unfortunately,
this requires $\log_2(n)$ bits to represent. So overall this approach
requires $O(n \log(n))$ space to play a simultaneous exhibition of $n$
games.

It appears to be possible to reduce the space usage per game to a
constant. In order to perform a man-in-the-middle attack, we need
a perfect matching between the white games and black games. It is
not essential that the matching be stable over time; for example
if we are forwarding moves between Walice and Bob, and between
Waluigi and Bario, and these games happen to transpose to the same
position, then it works just fine to switch to forwarding between
Walice and Bario; Waluigi and Bob. So, rather than store the
matching explicitly, we can reconstruct it from the stored state.
We two vectors of $n/2$ rows, the ``source'' and ``destination'' rows,  (XXX I think we do not need destination)
each containing a game {\em position} (not move).
This position represents XXXX (like the last time we saw it?).
The positions are initialized to the starting position. Like before
we can be in one of four states:
\begin{itemize}
\item Waiting for all ``source'' players (who play as white) to complete their moves. \label{state:cmim1}
\item Forwarding our moves from ``source'' to our black opponents. \label{state:cmim2}
\item `` \ldots '' (who play as black) `` \ldots '' \label{state:cmim3}
\item `` \ldots '' white opponents. \label{state:cmim3}
\end{itemize}

\newcommand\stepsto[1]{\stackrel{#1}{\rightarrow}}

% (XXX So actually, simpler here is just: Loop until all white players have
% made their moves. Then copy all their boards to our board vector.)
While in State~\label{state:cmim1} (which we also start in), we
compare our stored source board states to the boards where we play as
black. Once the white opponent has made a move, resulting in $B'$,
there will be some position $B$ in our ``source'' set that is a valid
predecessor for $B'$ (that is, there exists some legal move $M$ that
advances $B$ to $B'$). For example, at the beginning, $B$ may be the
starting position (in fact it must, since all boards are initialized
this way) and $B'$ may be the position resulting from $1. e4$. With
the matching constructed (see below) we copy each $B'$ into our set of
boards, forgetting $B$.\footnote{In fact, we do not even need to
  construct the matching, although it may help us with bookkeeping
  (e.g., which games have already been copied?), depending on how the
  exhibition itself is represented.} Then we transition to
State~\label{state:cmim2}. In this state, we figure out what moves to
play in the pending boards. By invariant, each one $B$ will be
compatible with at least one of our source boards $B'$; we can iterate
over source boards until we find one in constant space (and mark it
as ``taken'' with . Compatible
means that there exists a move $m$ where playing $m$ in board $B$
results in $B'$. If $m$ exists, it is unique (and easy to compute), so
this is the move that we will play. The only tricky thing is figuring
out which boards go with which; this is the problem of reconstructing
the perfect matching.

Although if $B \stepsto{m} B'$ it is easy to deduce $m$, it is not
possible to compute $B$ from $B'$, or even from $B'$ and $m$. This is
because we may have both $B_a \stepsto{m_a} B'$ and $B_b \stepsto{m_b}
B'$ with $B_a \neq B_b$. For example with $B'$

\chessboard[tinyboard, setfen=k7/8/8/8/8/8/8/K7 w - -, showmover]

we could have $B_a$ and $B_b$ be

\chessboard[tinyboard, setfen=Nk6/8/8/8/8/8/8/K7 b - -, showmover]
\chessboard[tinyboard, setfen=Rk6/8/8/8/8/8/8/K7 b - -, showmover]

Both of which can precede $B'$ (the move is even the same: Kxa1).
So it is not enough to greedily assign edges in our perfect match;
if we choose the edge $B_b$ to go with $B'$, we might later find
$B'_2$:

\chessboard[tinyboard, setfen=R7/1k6/8/8/8/8/8/K7 w - -, showmover]

\ldots and have no possible matching board, since it cannot follow
$B_a$.

Fortunately, we know that there exists a perfect matching (assuming
all players are playing legal moves) and we can tell if we found
one (i.e., we didn't get stuck). So, one strategy that works is
to choose randomly when there is some ambiguity, and start over
from the beginning if we ever get stuck. In practice this will
be pretty efficient, since convergent board states are unusual.
We only need a single pseudorandom pool for the entire process,
so it can be O(n) bits; this seems easily enough to generate all
possible permutations of $n/2$ items. Even $n^{2n}$ grows much
faster than $n!$. If we don't like the random approach, I believe
it is also possible to compute \verb+next_permutation+ in
constant space; so we can just explicitly try all orderings for $B'$
(this takes exponential time).

Once we have paired up each $B$ and $B'$, we simply compute the
move (which we now know exists) and play it in that game. We
then wait for the black opponents to play their moves, copy the
resulting board states into our vector and repeat the above
process (but flipping ``black'' and ``white'').

Although this is more involved than the previous approach, and may
take exponential time, it allows us to play against $n$ simultaneous
opponents using $O(n)$ space!\footnote{ 
%
If the games in the exhibition were presented to us in some way that
allowed us to visit them in the same order multiple times, we could
perhaps get away with {\em only} the random pool? XXX }

\subsection{Board representations} \label{sec:representation}

The actual space used per game is primarily the representation of
a chess position, plus a few bits for bookkeeping. So, representing
boards compactly gives us a way to increase the number of simultaneous
games we can play for a given storage size.

Mainly, we need to store the pieces and their locations. There are a
few other bits, like whose turn it is (1 bit), whether each player can
still castle king- and queen-side (4 bits), and whether and where an
en passant capture is possible (4 bits).\footnote{
%
Technically, we need to store a lot of additional information with the
board in order to completely implement the rules of
chess.\cite{fiderules} The trickiest of these involve the rules for
draw by repetition, which make reference to the history of the game
(See Footnote~1 in {\it Survival in chessland}\cite{survival} and seem
to require storing all previous board states. Fortunately, if we are
being this picky, then we also know that the length of a chess game is
bounded by a constant: Rule 9.6.2 ends the game in a draw if both
players have made 75 moves without a pawn move or
capture,\footnotemark\ so it suffices to store the $75\times 2$ most recent
(half-)moves. This sucks so most people don't do it (for example, FEN
notation only gives the number of such moves, and so cannot implement
the draw by repetition). On the other hand, if we insist, then this
may give us a simpler route to a constant-space exhibition, since the
$B \stepsto{m} B'$ relation is probably reversible with such
information.}\footnotetext{These are two types of moves that make it impossible
  to formally repeat a position that preceded them. Castling also has
  this property, but doesn't count because it is a ``secret move.''}

With 64 squares, six pieces for each of the two sides, plus the empty
square, a straightforward representation of the board uses $64 \times 4=256$
bits. The Thursd'z Institute considered more compact
representations\cite{representations}; one nice choice works as follows:

Start with a single 64-bit mask which indicates, for each square on
the board, whether it contains any piece. Note that there can only be
up to 32 pieces on the board. To tell what these pieces are, we then
follow with 32 four-bit records; these indicate the piece's color and
type.\footnote{(Since only 32 of the 64 bits can be set, you could do
  slightly better by representing $\binom{60}{32}$ in $\sim 61$ bits.
  When fewer than 32 squares are occupied, we can use a record
  containing e.g. a third king (otherwise impossible) to indicate that
  we should ignore the remaining bits. However, this gets vastly more
  complicated for only 3 bits of savings.)} 
%
With the 9 bits of extra state above, this totals $64+32 \ times 4+9=201$
bits. There is some slack in the representation, because there are
only 12 actual possibilities for a piece but we can indicate 16 with 4
bits. It is great to abuse this slack to save bits; for example, we
can store a new type of rook that is still able to castle (it can only
be in the corners and thus also indicates its own color), eliminating
the 4 castling bits. We can similarly introduce an en-passantable
pawn, saving the 4 bits of en passant state; this piece can only be in
ranks 4 or 5, so it also indicates its color. We can also have a
``king whose turn it is'' for each side, saving the side-to-move bit.
This totals a nice round $64+32 \times 4=192$ bits.\footnote{ Since this is
  SIGBOVIK, I am freed from the burden of comparing related work. I
  did however read the rather bad Wikipedia article on the
  topic\cite{wikipediaboard} which describes a Huffman-based encoding
  that uses a ``maximum of 204 bits, and often much less.'' This also
  includes a 7-bit 50-move counter (but you really need to implement a
  75-move counter; 50 moves only allow a player to {\em claim} a draw)
  so should be compared as $197$ bits. But the article also contains
  many bugs, like the misconception that there can only be four total
  rooks (pawns are allowed to promote to rook). So the approach
  described here is both {\em more efficient} and {\em more correct}.}
%
This would allow approximately an 11 billion-game simultaneous
exhibition in RAM on my desktop computer.

\medskip
So now comes the main idea of the paper, which is also spoilered in the
very clear paper title. What if we represented boards {\em only} as the
64-bit mask telling us what squares are occupied? The encoding is very
lossy, of course, but it often contains enough information to deduce
the state of the board. For example, can you tell what position this is?

\chessboard[setfen=8/8/8/8/8/8/8/8,
  showmover=false, 
  smallboard,  
  color=gray,
  strokeopacity=0,
  markstyle={[fill]circle},
  markfields={a1,b1,c1,d1,e1,f1,g1,h1,a2,b2,c2,d2,e4,f2,g2,h2,a7,b7,c7,d7,e7,f7,g7,h7,a8,b8,c8,d8,e8,f8,g8,h8
}]

Correct! It is

\begin{tabular}{p{1.85in}p{1.4in}}
\chessboard[setfen=nrbqkbrn/pppppppp/8/8/4P3/8/PPPP1PPP/NRBBNRQK b - - 34 19, showmover=false, smallboard] & {
\vspace{-1.65in} \small after 1. Nf3 Nf6 2. e4 Ng4 3. Bc4 Ne5 4. O-O Ng6
5. Kh1 Rg8 6. Nc3 Nh8 7. Qe2 Nc6 8. Rb1 Rb8
9. Nb5 Nb4 10. Rd1 Nd5 11. Qf1 Nb6 12. Qg1 Na8
13. Nbd4 Nb6 14. Rf1 Na8 15. Be2 Ng6 16. Bd1 Nh8
17. Nb3 Ng6 18. Ne1 Nh8 19. Na1}
\end{tabular} \vspace{1em}

\section{Color- and piece-blind chess}

So this is kind of like blindfold chess, but for computers! Instead of
being blind to the board, and only relying on our memory (trivial for
computers), we'll only be able to see where pieces are positioned on
the board, but not what type or color they are. Of course, we also
have to prohibit the computer from simply remembering the board, so
the algorithm must be stateless. Specifically, we want a function
\[
  {\tt makemove} : {\tt uint64} \rightarrow {\tt move list}
\]
that makes a move from a single board position, represented just as 64
bits. This is a single move; the move list represents our preference
for the move to make in descending order, and we commit to the first
move that is actually legal. It does not work well to insist that the
function return a single move, as it will often be the case that the
board is misinterpreted and a move is in fact illegal; forcing
forfeit\footnote{FIDE rules state that the {\em second} attempt at an
  illegal move results in forfeit (7.5.5).} would mean that almost all
games end in forfeit, which is boring. On the other hand, allowing the
function to try again upon learning a move is illegal would allow it
to interactively ``interrogate'' the board state
somewhat.\footnote{Similar to Kriegspiel~\cite{wikipediakriegspiel}, although
  in that game at least one's own pieces are known!} This seems
counter to the spirit of color- and piece-blind chess, so we instead
require the function to rank all moves ahead of time.

\section{Unblinding the board}

I went about this by building a function that ``unblinds'' a board; it
has type
\[
{\tt unblind} : {\tt uint64} \rightarrow {\tt position}
\]

This function is natural for machine learning. It is easy to generate
copious training data from actual games by simply blinding positions
into their corresponding 64-bit numbers; I just randomly sampled 100
million positions from Feburary~2017 on lichess.org.

I repurposed the custom neural network code from my seminal paper {\it
  Red i removal with artificial retinal networks}~\cite{redi} after
discovering that artificial retinal networks are actually {\em
  isomorphic} to neural networks. The main advantage of this code is
that it allows for sparse networks, but the real reason to use it is
that I would rather spend dozens of hours debugging my own code, pay a
larger electric bill, and get worse results in the end, than to spend
a short while trying to get someone else's probably-very-good neural
network training package to compile.

The structure of the network is as follows. The input layer is 64
nodes, one for each of the 64 bits, with each node set to either {\tt
  1.0f} or {\tt 0.0f}. Three hidden layers of size 1024, 12288, and 567
do the neural magic. The output layer is 837 nodes; the bulk of which
is a ``one-hot'' representation of the predictions for the 64 squares,
each with 13 possible contents (black or white, six pieces, or empty).
This is $64 \times 13 = 832$ nodes. Then four nodes to predict the
four castling bits, and one to predict the current side to move. This
model does not predict the possibility for {\em en passant} capture,
nor move counters or position repetition. This will not be its main
source of disadvantage!

I trained the network in two phases, first starting with a densely
connected one (model size 160 MB), and then after I get fed up with
how slow training was, a ``vacuumed'' version of the network where I
removed edges with low absolute weights (model size 5 MB) to continue
training. Removing edges based on an absolute weight threshold is
very unprincipled (since a downstream edge can magnify a contribution
arbitrarily) but I did it anyway.

Everything was trained on a single GPU, though a fairly decent one in
2018, the EVGA GeForce GTX 1080 FTW (really), using OpenCL. Biases
were initialized to $0$ and weights with a Gaussian of mean $0$ and
standard deviation $0.025$. In the first phase, there were 64 examples
per round, and after vacuuming, 2048. The round learning rate
$\alpha_r$ started at $0.1$ and descended linearly to $0.002$ over
500,000 rounds; and the learning rate when updating weights (for each
example) $\alpha$ is $\alpha_r / \verb+examples_per_round+$. In no way
am I recommending these parameters. Fiddling with the parameters to
make it do its black magic or alternately carom off to a sea of NaNs
or zeroes is for sure the worst part of neural networks. In fact, I
initially started with the classical sigmoid transfer function, but
``upgraded'' to the ``leaky rectified linear'' function
%
$$(p < 0) \,?\, p \times 0.01 : p$$
%
after getting fed up with sigmoid weights caroming off (see
``vanishing gradient problem'' and/or ``exploding gradient problem'').
The final model was trained over 339,885 rounds on 223 million
examples. It did not appear to show signs of improving for
several days before I terminated it.

\subsection{Statistical evaluation}

The unblinding component can be evaluated on its own, by running it on
examples sampled independently of the training set. The model outputs
a score for each possible contents of each square; we simply
discretize to the highest-scoring one (same too for the predicted
castling state and turn). Over 50,000 examples, these were the
results:

9,584 predicted boards were exactly correct (19.17\%). There were a
total of 161,166 piece mistakes, which is an average of 3.22 per
board. This is wherever we predict a square's contents incorrectly.
There were only 1630 castling status mistakes, an average of 0.03 per
board (there can be up to four mistakes per board). This is probably
because when the king and rook are in their starting squares, castling
is almost always still allowed. In 19,014 boards, we mispredicted
whose move it is (38\%). This appears to be the most difficult thing
to predict, which is not surprising.\footnote{ Prior to ``vacuuming'',
  the 160 MB network actually performed slightly better than the final
  5 MB network, with 21.20\% of boards exactly correct, and an average
  of 3.12 mistakes per board. This suggests that the model may only be
  doing a limited amount of generalization, instead mostly memorizing
  board positions. Representing the 223 million examples seen exactly
  (using our best board representation described in
  Section~\ref{sec:representation}) would take 42.8 GB, so at 5 MB at
  least the data is represented compactly, if also rather lossily.}

\subsection{Subjective evaluation}

The unblinder {\em must} make mistakes since the 64-bit representation
is ambiguous. Subjectively, the unblinder makes reasonable mistakes.
It is excellent at common openings, usually getting these exactly
correct. On the other hand, it is fairly bad at sparse endgames, where
it is difficult to tell a pawn from a rook from a king. It is terrible
at unlikely positions that can be confused for likely ones. If you are
playing against it and know how it works, it is easy to trick it by
doing something like capturing one of its starting-position pawns with
your queen; nobody does this in real games (because the queen can be
immediately recaptured), so the square is predicted as a pawn and the
queen ``disappears'' to the unblinder (Figure~\ref{fig:trick}). Having
an invisible queen in your camp is of course very dangerous. Resolving
ambiguities in favor of more likely positions is the right thing for
the model to do, so this is just an inherent flaw with the
decomposition of the problem. There are some ways we can account for
this (Section~\ref{sec:using}). % XXX make sure I did this work

\begin{figure}[ht]
XXX actual example
\caption{The white queen ``disappears'' after QxWhatever, because
  unblinding predicts it to be one of black's own pawns, which is far
  more likely in that square.} \label{fig:trick}
\end{figure}

A few things are distinctly disappointing about its performance. Even
outside of ``likely'' positions, it usually predicts that pieces on
black's side of the board are black, and vice versa
(Figure~\ref{fig:allon}). This makes sense, but suggests serious
limitation on using the prediction to play chess. Less forgivably, it
sometimes predicts more than one king per side (or zero), which is
always wrong. Actually, an early version had this problem in spades,
usually frequently predicting two or three kings. Upon debugging, I
had simply made the noob mistake of printing both King and Knight with
the letter ``K.'' Ha! It often predicts the ``wrong'' number of
bishops (etc.), or places them on the same color. This is technically
possible through promotion, but usually a bad guess, since promotion
is relatively rare, and moreso promotion to a piece other than a
queen. An approach that might handle this better (but may have
different downsides) would be instead to predict the ``fates'' of the
32 initial pieces~\cite{survival}. The fate of a pawn includes what if
any piece it has promoted to, but no other pieces can. This would {\em
  require} that the model only predict a single location for each
king, among other things. However, this would require a much larger
output layer (32 pieces can move to 64 squares, plus promotion) and it
is not always clear how to interpret its value into a position (for
example, if two pieces are predicted strongly to be on the same
square).

\begin{figure}[ht]
\includegraphics[width=0.9 \linewidth]{blind-allon}
\caption{What the model predicts (in single-king mode;
  Section~\ref{sec:using}) for {\tt 0xFFFFFFFFFFFFFFFF}, the board
  with all bits set. This is an impossible position, but it gives some
  idea of the model's biases for each square. Notably, most of the pieces
  on each half of the board have a single color. This makes sense, but
  also suggests substantial limitation. When single-king mode is off,
  the bottom right king is predicted as a white rook.} \label{fig:allon}
\end{figure}

\section{Playing blind}

Once we have predicated a board state, we can play with it. The
simplest way to do this is to use a strong chess engine to pick a move
for the position. Here, I use Stockfish with a node budget of 1
million nodes, which takes about 1 second of CPU time per move on my
computer; henceforth {\sf stockfish1m}.

There are some complications:
\begin{itemize}
\item Frequently, the unblinded board will not match the true
  position, and Stockfish will choose a move that is illegal. So, as discussed
  before, we actually return a prioritzed list of moves. For this first
  experiment, we just return the move Stockfish recommends, followed by all
  other moves ordered randomly.
\item Stockfish is a very strong engine, and in my opinion the code is generally
  good, but it is very sensitive to bad FEN (the notation used to give it a
  position to evaluate) strings. Given a bad string, like one that says castling
  is possible when the king isn't in its home square, often crashes the engine.
  So we need to make sure to actually pass valid positions. I accomplish this
  by making the following modifications to the predicted board:
  \begin{itemize}
  \item If a castling bit is set, but castling is not possible due to the position
    of the king or rook, I clear the bit.
  \item Set the side-to-move to be the correct actual value. This uses
    the unblinded state, so is superficially cheating. But note that
    if we get the side wrong, then Stockfish's move will always be
    illegal: Moves are specified as a source and destination
    square,\footnote{Plus promotion piece. Castling is represented as
      a two-square move of the king.} and so the source square of
    Stockfish's move would always be a piece of the wrong piece's
    color. So this is equivalent to (but twice as efficient as)
    running stockfish twice, one for each side, and prioritizing the
    predicted side's move first.
  \end{itemize}
  This won't fix all positions, for example, if the white and black king are
  adjacent to one another in mutual check. If an irreparable problem is detected,
  then I just return a uniformly random move list.
\end{itemize}

It is easy to beat this chess engine, by tricking it as in
Figure~\ref{fig:trick}, although this involves unnatural moves, so it
may only apply if you know how it works.
% XXX example game?
Measuring how well it plays in an absolute sense is a subject of some
interest, so I wrote a separate paper about that~\cite{eloworld}. This
algorithm, called \verb+blind_yolo+, had an Elo World score of XXX.

\subsection{We three kings}

When evaluating the first version I found that it was predicting a
disappointingly high number of illegal positions in practice, which
was causing us to fall back on making random moves, which is mostly
boring. The second version reduces the rate of illegal positions due
to too many or too few kings~\cite{kingme}.

The model predicts a score for each type of piece in each square,
and we do not have to necessarily interpret it by always taking
the highest-scoring piece. This version first finds the two squares
with the highest scores for the white king, and same for the black
king. We take two in case the same square is predicted for both.
Then this square gets one of the kings (whichever has higher score)
and the other king goes in the highest-scoring unclaimed square. The
rest of the squares just get the highest-scoring prediction as before,
but we never predict kings.

This version, called \verb+blind_kings+, performs consistently better
than \verb+blind_yolo+ (63 wins, 45 losses, 412 draws).
% XXX could run a lot more games between these two.
% as white: 31/24/207, as black 21/32/205
It had an Elo World score of XXX.

\subsection{Spy check}

Say \verb+blind_kings+ is playing as black; it remains easy to fool it
by moving black pieces into white's camp, since they are usually then
predicted to be white pieces. We can defend against this somewhat.
Since it is illegal to capture one's own piece, there is little risk
in trying; if it is indeed our own piece then the move will be
rejected, and if it is not our piece, then capturing is good for two
reasons: One, we capture a piece, and two, we avoid having
Stockfish make a move in this incorrectly predicted board. (Of course
there are many reasons why eagerly capturing a piece can be a bad
idea, but at this level of play, an edge in material is likely worth
it.)

There is one subtlety here. Above we argued that it was safe to use
the actual side-to-move instead of the predicted one; but here it
would not be equivalent to do so. Instead, we first prioritize all
apparent spy-check moves where the predicted source piece matches the
predicted side-to-move, then we try the opposite. (Ties are broken by
preferring to capture with a lower-value predicted piece, and then
randomly.) Due to this, there is some additional chance that we end up
making an especially dumb move because we both mispredicted the
side-to-move and the identity of some pieces.

(XXX evaluation here)

\subsection{Future work}

The predicted board often expresses uncertainty about some squares,
which could be thought of as probabilities. A principled improvement
would be to try to find moves that are good in expectation, that is,
integrated all possible boards in proportion to their predicted
probability. A good approximation might be had by sampling a bunch
of boards according to the predicted distribution, and then using
Stockfish to score the top $k$ moves for each; we can then order
moves by their expected score. Unfortunately, it is not easy to
efficiently get Stockfish to generate scored moves for $k \neq 1$.
Even with $k = 1$, this approach would be slow, taking about a
second for each (distinct) sampled board. So I did not try it,
at least not before submitting this paper.



\section{Conclusion}



- Other structures for the network
- How do the solutions compare to other chess algorithms that
  could be applied in the blind? Random works, also lexicographic,
  any others? Most are inspecting the board state, obviously.
- Could estimate the upper bound for accuracy by blinding every
  game in the database, and doing a ``lookup''-based version of
  the eval.


% % make -j eval-unblinder.exe && ./eval-unblinder.exe net.val
% .!Evaluating model net.val...
% Loaded 50000 positions in 122.59s
% Loaded model in 0.10s
% Ran eval in 2.04s
% Reading [net.val]
% net.val: 4 layers.
% net.val: num nodes: 64 1024 12288 567 837
% net.val: indices per node/fns: 49 LEAKY_RELU 36 LEAKY_RELU 127 LEAKY_RELU 78 LEAKY_RELU
% Read from net.val.
% Invert index:
% Check it:
% ModelInfo [339885 rounds, 223224128 examples]
% Over 50000 positions:
%   9584 exactly correct (19.17%)
%   161166 piece mistakes (3.22/pos)
%   1630 castling mistakes (0.03/pos)
%   19014 move mistakes (0.38/pos)
%   181810 total mistakes (3.64/pos)
% 
% % $ make -j eval-unblinder.exe && ./eval-unblinder.exe net-before-vacuum.val
% make: 'eval-unblinder.exe' is up to date.
% Evaluating model net-before-vacuum.val...
% Loaded 50000 positions in 118.80s
% Loaded model in 3.99s
% Ran eval in 332.10s
% Reading [net-before-vacuum.val]
% net-before-vacuum.val: 4 layers.
% net-before-vacuum.val: num nodes: 64 1024 12288 567 837
% net-before-vacuum.val: indices per node/fns: 64 LEAKY_RELU 1024 LEAKY_RELU 12288 LEAKY_RELU 567 LEAKY_RELU
% Read from net-before-vacuum.val.
% Invert index:
% Check it:
% ModelInfo [146999 rounds, 9407936 examples]
% Over 50000 positions:
%   10601 exactly correct (21.20%)
%   156052 piece mistakes (3.12/pos)
%   1542 castling mistakes (0.03/pos)
%   18818 move mistakes (0.38/pos)
%   176412 total mistakes (3.53/pos)
% 
% 
% 
% without concurrent processes:
% net.val: 1.61s  (something like 1035/sec/core)
% net-before-vacuum: 229.85s (something like 7/sec/core)
% 
% 
% single_kings net.val:
% Over 50000 positions:
%   9642 exactly correct (19.28%)
%   162804 piece mistakes (3.26/pos)
%   1633 castling mistakes (0.03/pos)
%   19014 move mistakes (0.38/pos)
%   183451 total mistakes (3.67/pos)
% 
% It's actually kind of heartening that it performs worse with this approach,
% though we are more likely to get the whole board correct.
% 
% (cite #kingme)
% 

\bibliography{chess}{}
\bibliographystyle{plain}

\end{document}
