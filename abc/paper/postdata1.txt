
    ** The ladder **

To solve the various problems with  jumps, we build the program around
what's called a  "ladder" in the code. The whole  program is broken up
into small  blocks of code.  Each one  is given a  sequential "number"
(this has nothing to do with the memory location, just its sequence in
the list  of blocks). Each  block starts with  a "rung," which  is the
following code

    DEC SI
    JNZ +disp8

where disp8 is  a printable displacement that brings us  downward to the
next block. We decrement  the SI register to count down  to the block we
want, and if it is Not Zero yet,  then we jump to the next one. If zero,
we execute the block. Inside a block,  if we ever want to perform a jump
to some arbitrary block dest_block, then we can compute:

    offset = (dest_block - current_block) mod num_blocks
    si = (if offset = 0 then num_blocks else offset)
    jmp to next rung

Every block knows its current number,  so the offset is just a constant.
Note  that the  destination block's  number  may be  before the  current
block,  which is  why we  need  to mod  by  the total  number of  blocks
(yielding a non-negative  result). SI cannot be zero,  because the first
thing we do is DEC it, so  a self-loop requires setting to num_blocks, a
full cycle.

To perform  a jump to  a code location not  known at compile  time (e.g.
from a return  address (block number) on the stack,  we can just perform
the same computation as above. We do not have an efficient mod operation
(implementing  it seems  to need  loops,  in fact,  a circularity!),  so
instead we  actually compute (dest_block -  current_block) + num_blocks.
This is always positive as needed, but requires forward jumps to make an
entire  cycle around  the entire  ladder ("Turn  the dial  to the  left,
passing zero and the first number...").

The blocks  are laid out  sequentially in the  program until we  get too
close to the end of the segment; when  we do, we make sure to perform an
unconditional jump  across the  segment boundary, wrapping  around. This
jump need not DEC SI. In fact, most programs do not fill the entire code
segment, so we end up padding the  end and beginning of the segment with
jumps to span  the unused space. For these padding  jumps, we definitely
don't want to DEC SI, both  because that's more instructions to execute,
and because we don't  know the amount of padding ahead  of time (see the
section on Assembling below).

There are many annoyances!

A jump cannot be too short (less than 32 bytes) or too long (127 bytes).


We don't have access to a non-conditional JMP instruction. There are a
few tricks for simulating it. When computing a jump to a known label, we
can just know the state of flags because we've just performed some
computation. Even when doing a jump to a computed block number, we know
that the result of subtraction is not zero, so we can always use the JNZ
instruction. Occasionally we need to do a jump without knowing our state
at all. XOR always clears the Overflow flag, so something like

    XOR AX <- [DI]
    XOR AX <- [DI]
    JNO disp

keeps AX unperturbed and always performs the jump. A little shorter is

    JNO disp
    JO (disp - 2)

which jumps to the same target whether  the Overflow flag is set or not,
but is more annoying because we need to keep track of two displacements.
(XXX)


    ** Assembling **

Assembling the program is the process of generating actual instruction
bytes (here, printable x86)  from some semi-abstract representation of
instructions (in  ABC, this is  the LLVMNOP language discussed  in the
next section). Assembling a program has a self-dependency: In order to
generate instructions like jumps and loads of addresses, the assembler
needs to know where  code is located. But in order  to know where code
is  located, the  assembler needs  to generate  it. In  most assembler
tasks, this is reasonably straightforward: When we need to generate an
instruction like  "MOV AX  <- offset  data", we just  emit "MOV  AX <-
0x0000" and save for later an  obligation to overwrite the zeroes with
the address  of "data", once  we know where  we placed it.  This works
because the  encoding of  the MOV  instruction is  the same  length no
matter what 16-bit value we load.  The same holds for JMP instructions
(with the caveat that smart assemblers can JMP+disp8 for nearby labels
and  JMP+disp16 for  further ones;  these instructions  have different
length) and others.

For the ABC compiler this step is quite bad:
 - Loading any immediate value has a length ranging from 0 bytes (it's
   already in the register) to like 16. It's dependent on both the value
   being loaded and the context (contents of registers).
 - The rungs that start each code block must be able to Jcc+disp8 all
   the way to the next block. This jump distance can't be too big, or
   else it can't be encoded (or is not printable).
 - Jumps within a block always target the next block, but the jump
   distance can't be too short (or the displacement byte is not
   printable).
 - Since blocks are numbered sequentially and relative addresses are
   computed modulo the total number of blocks, logical code addresses
   depend on the number of blocks and their order.

As a result, assembling is an iterative process. We take the program's
blocks and translate them  into position-independent machine code. One
positive thing  about the printable, non-self-modifying  subset of x86
is  that none  of the  instructions  actually depend  on what  address
they're placed at  (except perhaps a Jcc instruction  used to overflow
the  instruction pointer).  Still,  we don't  know  even the  relative
location of the  next block yet, so  we also record the  offset of the
displacement byte for any Jcc instruction we emit.

Next, we take these blocks and  attempt to allocate them into the code
segment.  This can  fail for  the reasons  above, usually  after we've
placed a block far enough from the preceding one that all jumps in the
first are printable  (at least 0x20 bytes), the rung  at the beginning
of  that block  can't  target  the second  (because  it  is more  than
0x7e+0x03 bytes  away). We gather  all such problem blocks  and bisect
the LLVMNOP code (blocks "fall  through," so this is equivalent). Then
we try again.  When we succeed, we can fill  in the displacement bytes
for the  Jcc instructions  to create valid  printable code.  There are
various opportunities to be smarter about this (for example, bisecting
the LLVMNOP  assumes that all  such instructions assemble to  the same
length, which is not remotely true); tox86.sml contains several ideas.

Since  the initial  instruction pointer  must be  printable, we  start
laying out blocks  towards the middle of the code  segment. If a block
would run  off the end  of CS,  then we need  to pad that  region with
jumps that  get up  close to  the end of  the segment  and then  do an
overflowing jump past CS:0xFFFF before  continuing layout. Once we run
out of blocks, we also need to pad any remaining code space with jumps
in order  to bring control  back to the  first rung, since  the ladder
needs to be a  complete cycle in order to work. It's  easy to pick out
the texture of this padding in the code segment (e.g. pages 14, 16).


    ** LLVMNOP **

Knowing our low-level  endpoint, I can now work  backwards through the
compiler. The compiler generally proceeds  by a series of intermediate
languages, the last of which is called LLVMNOP.

This language  is an assembly-like  language that has  explicit *data*
layout, but not not explicit *code* layout. By that, I mean that every
function knows the size and offset  of its locals and arguments in the
current local frame, and the size  and address of each global variable
is known, as well as the global's initial values (if printable). It is
akin to LLVM  [XXX cite LLVM], but doesn't really  have anything to do
with   it.  LLVM   is  an   excellent  tool   for  writing   compilers
(superficially, it  looks like a  good way to  write a new  C compiler
targeting  an  architecture  like  printable x86!)  but  isn't  really
suitable  for  this  project  because   it  assumes  that  the  output
architecture  has certain  standard operations  efficiently available,
which is frequently not the case for printable x86.

A sample of LLVMNOP constructs are:

 cmd  ::= Add tmp <- tmp
        | Xor tmp <- tmp
        | Push tmp
        | Pop tmp
        | Mov tmp <- tmp
        | Immediate16 tmp <- word16
        | Load16 tmp <- tmp
        | Store16 tmp <- tmp
        | Load8 tmp <- tmp
        | Store8 tmp <- tmp
        | ExpandFrame i
        | PopJumpInd
        | JumpCond cond, label
        | ...
        | Out8
        | Init
        | Exit

 cond ::=  Below tmp, tmp
        |  BelowEq tmp, tmp
        |  ...
        |  EqZero tmp
        |  True

LLVMNOP exists in both a "named"  and "explicit" version. In the named
version, temporaries  (tmp) are strings paired  with a size (16  or 32
bits). In  the explicit version, temporaries  are given as a  size and
offset from  the current temporary  frame (EBP). The named  version is
transformed to the  explicit version by the  process called Allocation
(below).

Commands are basically  assembly instructions that we might  have in a
more expressive architecture; note for example that we have Add, which
is not native in printable x86 (we implement it by computing the two's
complement negation, and then subtracting).  Even commands that have a
corresponding printable  x86 instruction  like XOR are  still compiled
into  multiple  opcodes,  since  they  read  and  write  arguments  to
temporaries,  not  registers.  We   discussed  the  implementation  of
operations like Load16, Immediate16, and Mov in a previous section.

A program  consists of a  series of  labeled blocks. JumpCond  pairs a
condition (signed  and unsigned  comparisons, etc.) with  a jump  to a
label. The  possible conditions  map to the  Jcc instructions  that we
have  available. Since  opcode  0x7F (Jump  Greater)  is not  actually
printable, all of the conditions "face less"; the condition Greater(A,
B) is  equivalent to Less(B, A).  An earlier phase does  this rewrite.
Also note that  in C, a < b  is an expression that can be  used in any
context,  not   just  for  control   flow;  here  the   comparison  is
inextricably linked  to a jump, since  CMP only sets FLAGS,  and FLAGS
can only be used for jumping.  An earlier phase removes the expression
forms as well,  without being too wasteful when  the programmer writes
"if (x < 1)" to begin with.

The only way to jump to a non-constant destination is with PopJumpInd,
which is  basically the RET  assembly instruction. It pops  an address
(block number) from the top  of the machine stack, and unconditionally
transfers control to that label (by  computing the number of blocks to
traverse, then jumping  to the ladder). This is indeed  used to return
from a function call, as well as to call a function through a function
pointer. It takes  its argument on the stack (as  opposed to using the
existing "Pop tmp" and then "JumpInd tmp") because while we're setting
up a function call, we need to move the temporary frame pointer, after
which point it is unsafe to access temporaries. The stack, however, is
a stable place to stash data.

Since we have some higher-level  operations like Mov available, we can
implement some delicate maneuvers like  function calls as sequences of
multiple commands.  On the other  hand, for some primitives  like Init
and Exit, there's no real value  in breaking them into smaller pieces.
Some other complex  primitives like Out8 have no  analogous feature in
C; these are provided  as sort of "intrinsics" that can  be used to do
low-level programming  in C. We'll discuss  Out8 in the Section  on IO
(XXX). Other  primitives, such as  one called  "Argv" that is  used to
initialize  the  argv  parameter  to main  during  initialization,  is
compiled  away when  we convert  to LLVMNOP.  In this  case, the  Argv
primitive just  creates a  global array  containing two  elements: The
second is zero ("null") as required  by the standard, and the first is
the  constant address  0x0081, which  is  a pointer  into the  Program
Segment Prefix  where DOS  stores the  command line  (untokenized; the
programmer must do any processing she desires).


    ** Temporary allocation **

Temporary  allocation  is fairly  standard.  We  use a  dataflow-based
liveness calculation to determine which temporaries interfere with one
another; if  two temporaries  of the same  size don't  interfere, then
they  can use  the  same slot,  so  they are  coalesced  into one.  We
prioritize coalescing temporaries  in a "Mov tmp1 <- tmp2"  so that we
get the no-op  instruction "Mov tmp1 <- tmp1"; this  is possible for a
great many Movs,  and allows us to  be much more regular  in the phase
that  generates  LLVMNOP  without  compromising  code  size.  We  then
prioritize  temporaries  that  appear  in  a  "Load16  tmp1  <-  tmp2"
instruction since we have a nice trick  for that one when both are the
same. After that, we just greedily coalesce temporaries until it is no
longer  possible. Fancier  register allocation  techniques like  graph
coloring  would  work  here  (this   part  of  the  compiler  is  very
traditional),  but there's  not  much  need: We  have  over 40  16-bit
temporaries,  all of  which are  just as  efficient to  access, so  we
mainly  just want  to keep  the total  number used  small so  that EBP
offsets are  printable. Having a  smaller temporary frame  size allows
deeper recursion, as well.

The compilation strategy ends up  storing almost all immediate results
in temporaries, which is not that suboptimal since all operations need
to be  between a register  and memory  anyway. However, many  pairs of
instructions could  keep a  just-computed value  in a  register rather
than bothering to write it. This  is not yet implemented, but the idea
is that we could introduce a  small number of registers (probably just
one?) in  addition to the numbered  temporaries, and use those  in the
output  of  Allocation. This  could  produce  significantly closer  to
hand-written code, without the need to change much in the backend.


    ** CIL **

The  intermediate language  that precedes  the named  LLVMNOP code  is
called  CIL,  for C  Intermediate  Language.  It's  intended to  be  a
desugared and more explicit version of  C. Some examples of the of CIL
grammar:

  signedness ::= Signed | Unsigned

  type ::= Pointer type
         | Code type, type list
         | Word32
         | Word16
         | Word8
         | ...

  builtin ::= B_EXIT | B_ARGC | B_ARGV | B_PUTC | B_OUT8

  value ::= Var v
          | AddressLiteral loc, type
          | FunctionLiteral name, type, type list
          | Word8Literal w8
          | Word16Literal w16
          | Word32Literal w32

  exp ::= Value value
        | Plus width, value, value
        | LessEq width, value, value
        | Load width, value
        | Promote width, width, signedness, value
        | Call value, value list
        | Builtin builtin, value list
        | ...

  stmt ::= Bind v : type = exp in stmt
         | Store width value = value in stmt
         | GotoIf cond, string, stmt
         | Return value
         | ...

And lots more  stuff. A program is a collection  of functions, each of
which is a collection of named statements (the stmt type is recursive,
with a single statement representing a series of C statements until we
reach a  Return or unconditional  Goto). Programs  also have a  set of
globals with initialization code for  them. Note that CIL has ML-style
lexically  scoped variables  which are  only  in scope  for the  given
block. Since  C's semantics for  variables allow them to  be addressed
and modified, we convert all C  variables into explicit loads from and
stores to memory.

This language is  typed, with one important use of  this being that we
determine the calling convention for a function pointer from its type.
(This includes  the size of the  return address slot, which  is on the
locals stack and shared between the  caller and callee, as well as the
number and sizes of the arguments,  also on the locals stack.) We make
the representation (Word8, Word16, Word32) of integral types explicit,
but signed and unsigned ints are  represented the same way (just as on
the  processor  itself).  Instead,  expressions  like  Promote  (which
converts  e.g. an  8-bit word  to a  16-bit word)  are explicit  about
whether they  perform sign  extension. We  are careful  to distinguish
between 8-, 16- and 32-bit quantities throughout the compiler, because
printable x86  has the ability to  work with all three  widths, and we
can produce significantly better code if we can use the correct width.
(As a simple  example, loading a 16-bit word is  much cheaper than the
zero-extended 32-bit version.)
